{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morenourey/ENTREGABLES/blob/main/transf_learning_catsanddogs_finetuning_data_augmentation_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrS_ZVRj4Hrb"
      },
      "source": [
        "![Nuclio logo](https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png)\n",
        "\n",
        "#Transfer Learning con la técnica de Fine Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWCs2GtMPAw"
      },
      "source": [
        "# Connectar a Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6Jk6GTVMDW_",
        "outputId": "7eeea977-711e-44f3-dbd1-333fa699aa0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5FTXWKIM1Dx"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YO-qvTSM3kX"
      },
      "source": [
        "from tensorflow import keras as ks\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.models import Model, load_model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGCNtaSOEPV"
      },
      "source": [
        "# Variables de entorno\n",
        "\n",
        "<font color=\"#FF0000\">Aquí definireis vuestra ruta del proyecto de perros y Gatos</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7K7GC8BQOHV9"
      },
      "source": [
        "ANCHO_IMAGEN = 150\n",
        "ALTURA_IMAGEN=150\n",
        "IMAGE_SIZE = (ANCHO_IMAGEN, ALTURA_IMAGEN)\n",
        "CANALES_IMAGENES = 3\n",
        "\n",
        "ruta_archivos = '/content/drive/MyDrive/NUCLIO/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CavLXOtgOTyb"
      },
      "source": [
        "# Cargaremos datos en NPZ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzVhzbmqOZ7i"
      },
      "source": [
        "dict_npz = np.load(ruta_archivos+'xy_train_img.npz')\n",
        "x_train_img = dict_npz['x']\n",
        "y_train_img = dict_npz['y']\n",
        "\n",
        "dict_npz = np.load(ruta_archivos+'xy_test_img.npz')\n",
        "x_test_img = dict_npz['x']\n",
        "y_test_img = dict_npz['y']\n",
        "\n",
        "dict_npz = np.load(ruta_archivos+'xy_val_img.npz')\n",
        "x_val_img = dict_npz['x']\n",
        "y_val_img = dict_npz['y']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsjYQW0OPCFL"
      },
      "source": [
        "x_train_scaled = x_train_img / 255.\n",
        "x_test_scaled = x_test_img / 255.\n",
        "x_val_scaled = x_val_img / 255."
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF_SnUJNPtZ5"
      },
      "source": [
        "# Montamos la Red Neuronal\n",
        "\n",
        "## Cargar la parte de extraccion de features de VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBi8HNOBP1V2",
        "outputId": "b210948e-97a9-408c-cf56-c256ebe15b63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vgg = vgg16.VGG16(include_top=False, weights='imagenet', input_shape=(ANCHO_IMAGEN, ALTURA_IMAGEN, CANALES_IMAGENES))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMTMdgQ9QvfS",
        "outputId": "2aa10d5e-3292-4be4-94fc-dc0bcc9b03b7"
      },
      "source": [
        "vgg.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14714688 (56.13 MB)\n",
            "Trainable params: 14714688 (56.13 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyLyT1BiGOPz"
      },
      "source": [
        "Como se puede ver en el summary, no tenemos capa Flatten de salida, así que creamos una Flatten basandonos en el output de la red neurona vgg. Y con Model() enganchamos una con la otra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm6mjIf8RD6z"
      },
      "source": [
        "output = vgg.layers[-1].output\n",
        "new_output_layer = ks.layers.Flatten()(output)\n",
        "vgg_model = Model(vgg.input, new_output_layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYrm_LhjR3e_",
        "outputId": "dacffe4b-4fb2-4739-8610-a85042decf3d"
      },
      "source": [
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 8192)              0         \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs6U8vf2GeNJ"
      },
      "source": [
        "Veamos si son entrenables o no dichas capas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv8dAyCqK8ET",
        "outputId": "860a8c59-1c70-4956-de44-48b67d29c9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Is model trainable?\", vgg_model.trainable)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is model trainable? True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FJHwZxrHG57",
        "outputId": "ecfcecec-0d45-4d7c-97be-0f2fdaebfde8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        }
      },
      "source": [
        "pd.set_option('max_colwidth', None)\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layer Type</th>\n",
              "      <th>Layer Name</th>\n",
              "      <th>Layer Trainable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fabe836aad0&gt;</td>\n",
              "      <td>input_1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabda071690&gt;</td>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd93836d0&gt;</td>\n",
              "      <td>block1_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd93c1590&gt;</td>\n",
              "      <td>block1_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfe60050&gt;</td>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfed0f50&gt;</td>\n",
              "      <td>block2_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd82ca850&gt;</td>\n",
              "      <td>block2_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd82e6590&gt;</td>\n",
              "      <td>block3_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0171650&gt;</td>\n",
              "      <td>block3_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd017c850&gt;</td>\n",
              "      <td>block3_conv3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd01711d0&gt;</td>\n",
              "      <td>block3_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd01848d0&gt;</td>\n",
              "      <td>block4_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd018d090&gt;</td>\n",
              "      <td>block4_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0194710&gt;</td>\n",
              "      <td>block4_conv3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd0184990&gt;</td>\n",
              "      <td>block4_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019ad90&gt;</td>\n",
              "      <td>block5_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0127510&gt;</td>\n",
              "      <td>block5_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019b0d0&gt;</td>\n",
              "      <td>block5_conv3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd012f350&gt;</td>\n",
              "      <td>block5_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.core.Flatten object at 0x7fabd013c450&gt;</td>\n",
              "      <td>flatten</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                          Layer Type  ... Layer Trainable\n",
              "0   <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fabe836aad0>  ...            True\n",
              "1     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabda071690>  ...            True\n",
              "2     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd93836d0>  ...            True\n",
              "3     <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd93c1590>  ...            True\n",
              "4     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfe60050>  ...            True\n",
              "5     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfed0f50>  ...            True\n",
              "6     <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd82ca850>  ...            True\n",
              "7     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd82e6590>  ...            True\n",
              "8     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0171650>  ...            True\n",
              "9     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd017c850>  ...            True\n",
              "10    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd01711d0>  ...            True\n",
              "11    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd01848d0>  ...            True\n",
              "12    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd018d090>  ...            True\n",
              "13    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0194710>  ...            True\n",
              "14    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd0184990>  ...            True\n",
              "15    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019ad90>  ...            True\n",
              "16    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0127510>  ...            True\n",
              "17    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019b0d0>  ...            True\n",
              "18    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd012f350>  ...            True\n",
              "19            <tensorflow.python.keras.layers.core.Flatten object at 0x7fabd013c450>  ...            True\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hIiMkD8GFqb"
      },
      "source": [
        "Vamos a activar como entrenables solo las convoluciones del bloque 4 para abajo, de ahí que hagamos el siguiente bucle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmSzCmK1SK7c"
      },
      "source": [
        "entrenable = False\n",
        "\n",
        "for layer in vgg_model.layers:\n",
        "  if layer.name == 'block4_conv1':\n",
        "    entrenable = True\n",
        "  layer.trainable = entrenable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "1Xr76uANSfx7",
        "outputId": "6c6314b1-bccf-4138-a74f-7bcdc3b3d51b"
      },
      "source": [
        "pd.set_option('max_colwidth', None)\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg_model.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Layer Type</th>\n",
              "      <th>Layer Name</th>\n",
              "      <th>Layer Trainable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fabe836aad0&gt;</td>\n",
              "      <td>input_1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabda071690&gt;</td>\n",
              "      <td>block1_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd93836d0&gt;</td>\n",
              "      <td>block1_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd93c1590&gt;</td>\n",
              "      <td>block1_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfe60050&gt;</td>\n",
              "      <td>block2_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfed0f50&gt;</td>\n",
              "      <td>block2_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd82ca850&gt;</td>\n",
              "      <td>block2_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd82e6590&gt;</td>\n",
              "      <td>block3_conv1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0171650&gt;</td>\n",
              "      <td>block3_conv2</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd017c850&gt;</td>\n",
              "      <td>block3_conv3</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd01711d0&gt;</td>\n",
              "      <td>block3_pool</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd01848d0&gt;</td>\n",
              "      <td>block4_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd018d090&gt;</td>\n",
              "      <td>block4_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0194710&gt;</td>\n",
              "      <td>block4_conv3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd0184990&gt;</td>\n",
              "      <td>block4_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019ad90&gt;</td>\n",
              "      <td>block5_conv1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0127510&gt;</td>\n",
              "      <td>block5_conv2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019b0d0&gt;</td>\n",
              "      <td>block5_conv3</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd012f350&gt;</td>\n",
              "      <td>block5_pool</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>&lt;tensorflow.python.keras.layers.core.Flatten object at 0x7fabd013c450&gt;</td>\n",
              "      <td>flatten</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                          Layer Type  ... Layer Trainable\n",
              "0   <tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fabe836aad0>  ...           False\n",
              "1     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabda071690>  ...           False\n",
              "2     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd93836d0>  ...           False\n",
              "3     <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd93c1590>  ...           False\n",
              "4     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfe60050>  ...           False\n",
              "5     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabdfed0f50>  ...           False\n",
              "6     <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd82ca850>  ...           False\n",
              "7     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd82e6590>  ...           False\n",
              "8     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0171650>  ...           False\n",
              "9     <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd017c850>  ...           False\n",
              "10    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd01711d0>  ...           False\n",
              "11    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd01848d0>  ...            True\n",
              "12    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd018d090>  ...            True\n",
              "13    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0194710>  ...            True\n",
              "14    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd0184990>  ...            True\n",
              "15    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019ad90>  ...            True\n",
              "16    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd0127510>  ...            True\n",
              "17    <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fabd019b0d0>  ...            True\n",
              "18    <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fabd012f350>  ...            True\n",
              "19            <tensorflow.python.keras.layers.core.Flatten object at 0x7fabd013c450>  ...            True\n",
              "\n",
              "[20 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO4I17PxUVOS"
      },
      "source": [
        "# Montemos la red de VGG16 + Clasificación\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ro2wPiG1UZX0",
        "outputId": "bc7e8ead-91ff-4215-efc3-6508fdfb2d26"
      },
      "source": [
        "input_shape = vgg_model.output_shape[1]\n",
        "\n",
        "print('Tamaño de entrada:', input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tamaño de entrada: 8192\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qDwi_ELUwHg",
        "outputId": "41c0d2be-9c5a-4d6a-d072-3ae806097b3e"
      },
      "source": [
        "model_with_vgg = ks.Sequential()\n",
        "\n",
        "model_with_vgg.add(vgg_model)\n",
        "model_with_vgg.add(ks.layers.Dense(512, activation='relu', input_shape=(input_shape,)))\n",
        "model_with_vgg.add(ks.layers.Dropout(0.3))\n",
        "model_with_vgg.add(ks.layers.Dense(512, activation='relu'))\n",
        "model_with_vgg.add(ks.layers.Dropout(0.3))\n",
        "model_with_vgg.add(ks.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_with_vgg.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "model (Functional)           (None, 8192)              14714688  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               4194816   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 19,172,673\n",
            "Trainable params: 17,437,185\n",
            "Non-trainable params: 1,735,488\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgyjckmLWGV5"
      },
      "source": [
        "# Creamos un optimizador\n",
        "\n",
        "Como la red es muy compleja (más de 17 millones de parámetros), necesitamos un learning rate muy bajo, por eso creamos un Adam específico con un learning rate de 0.00002 (2e-5)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D-G7bQ2WKZL"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lv5_11kWaP0"
      },
      "source": [
        "new_adam = Adam(learning_rate=2e-5)\n",
        "new_sgd = SGD(learning_rate=2e-5, momentum=0.9)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGPweTyGWwiA"
      },
      "source": [
        "model_with_vgg.compile(loss='binary_crossentropy', optimizer=new_sgd, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFrHu2sXCQB"
      },
      "source": [
        "# Early stopping!!\n",
        "Montamos la monitorización del error de validación con paciencia de 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20hx0uQFXA08"
      },
      "source": [
        "earlystop = EarlyStopping(monitor='val_loss', patience=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rH-807oFOLTU"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZKWdR2Na3Mm"
      },
      "source": [
        "# Model Checkpoint\n",
        "Montamos la monitorización para ir guardando el mejor modelo del entrenamiento con mejor accuracy de validacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvV2t_SuOeGe"
      },
      "source": [
        "modelcheckpoint = ModelCheckpoint('/tmp/chkpoint', monitor='val_accuracy', save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sCOQagoO6gD"
      },
      "source": [
        "# Preprocesamos las etiquetas con el LabelEncoder\n",
        "\n",
        "Hay que recordar que las etiquetas han de tener el formato [value1, value2, ... valueN] porque el ImageDataGenerator no sabe que hacer si las etiquetas son [[value1], [value2],... [valueN]]\n",
        "\n",
        "¡En ese caso hay que hacer un .ravel() al array!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNzsi3Sa89O"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train_img)\n",
        "y_train_encoded = le.transform(y_train_img)\n",
        "y_val_encoded = le.transform(y_val_img)\n",
        "y_test_encoded = le.transform(y_test_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx2qT33pbWfy",
        "outputId": "172508da-b2f2-4fd8-9a52-002e51953f4d"
      },
      "source": [
        "print(np.array(y_train_img))\n",
        "print(np.array(y_train_encoded))\n",
        "\n",
        "y_train_encoded"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['cat' 'cat' 'cat' ... 'dog' 'dog' 'dog']\n",
            "[0 0 0 ... 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpS9N9yPw4oX"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "Como la red es muy compleja hemos de ir con cuidado con el batch_size de los generadores de imagenes, que no superen los 32 elementos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5P3JRqUw8B2"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "train_generator = train_datagen.flow(\n",
        "    x_train_img,\n",
        "    y_train_encoded,\n",
        "    batch_size=30\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HICf1VGixjP0"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        "    )\n",
        "validation_generator = validation_datagen.flow(\n",
        "    x_val_img,\n",
        "    y_val_encoded,\n",
        "    batch_size=20\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ewPTEFXOPb"
      },
      "source": [
        "# Entrenar\n",
        "\n",
        "Al montar el data augmentation los steps per epochs y los validation steps hay que definirlos:\n",
        "\n",
        "steps_per_epochs = total imagenes / batch_size del train generator = 5000 / 30 = 167<br>\n",
        "validation_steps = total imagenes validacion / batch_size del validation generator = 1000 / 20 = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nLdIY2UXY4s",
        "outputId": "98c805a4-885d-427e-e3b8-890ce466e4ad"
      },
      "source": [
        "history = model_with_vgg.fit(train_generator, epochs=200, steps_per_epoch=167,\n",
        "                             callbacks=[modelcheckpoint, earlystop],\n",
        "                             validation_data=validation_generator, validation_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "167/167 [==============================] - 71s 213ms/step - loss: 0.7280 - accuracy: 0.5028 - val_loss: 0.6754 - val_accuracy: 0.5730\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 2/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.7028 - accuracy: 0.5292 - val_loss: 0.6337 - val_accuracy: 0.7190\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 3/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.6742 - accuracy: 0.5728 - val_loss: 0.5922 - val_accuracy: 0.7910\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 4/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.6368 - accuracy: 0.6382 - val_loss: 0.5429 - val_accuracy: 0.8200\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 5/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.6098 - accuracy: 0.6710 - val_loss: 0.4914 - val_accuracy: 0.8260\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 6/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.5560 - accuracy: 0.7250 - val_loss: 0.4478 - val_accuracy: 0.8250\n",
            "Epoch 7/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.5112 - accuracy: 0.7612 - val_loss: 0.3960 - val_accuracy: 0.8450\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 8/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.4720 - accuracy: 0.7884 - val_loss: 0.3682 - val_accuracy: 0.8520\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 9/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.4416 - accuracy: 0.8000 - val_loss: 0.3312 - val_accuracy: 0.8740\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 10/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.4137 - accuracy: 0.8100 - val_loss: 0.2945 - val_accuracy: 0.8910\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 11/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.3824 - accuracy: 0.8348 - val_loss: 0.2794 - val_accuracy: 0.8900\n",
            "Epoch 12/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.3641 - accuracy: 0.8434 - val_loss: 0.2544 - val_accuracy: 0.9020\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 13/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.3400 - accuracy: 0.8580 - val_loss: 0.2351 - val_accuracy: 0.9090\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 14/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.3286 - accuracy: 0.8590 - val_loss: 0.2393 - val_accuracy: 0.9000\n",
            "Epoch 15/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.3117 - accuracy: 0.8712 - val_loss: 0.2196 - val_accuracy: 0.9170\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 16/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.3056 - accuracy: 0.8768 - val_loss: 0.2138 - val_accuracy: 0.9170\n",
            "Epoch 17/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.2964 - accuracy: 0.8800 - val_loss: 0.2374 - val_accuracy: 0.9100\n",
            "Epoch 18/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.2920 - accuracy: 0.8750 - val_loss: 0.2022 - val_accuracy: 0.9180\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 19/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.2802 - accuracy: 0.8844 - val_loss: 0.2226 - val_accuracy: 0.9200\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 20/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.2770 - accuracy: 0.8872 - val_loss: 0.1869 - val_accuracy: 0.9270\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 21/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.2609 - accuracy: 0.8950 - val_loss: 0.1870 - val_accuracy: 0.9270\n",
            "Epoch 22/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.2524 - accuracy: 0.8972 - val_loss: 0.1791 - val_accuracy: 0.9290\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 23/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.2491 - accuracy: 0.8964 - val_loss: 0.1876 - val_accuracy: 0.9280\n",
            "Epoch 24/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.2381 - accuracy: 0.9050 - val_loss: 0.1964 - val_accuracy: 0.9270\n",
            "Epoch 25/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.2390 - accuracy: 0.8976 - val_loss: 0.2165 - val_accuracy: 0.9280\n",
            "Epoch 26/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.2295 - accuracy: 0.9078 - val_loss: 0.1713 - val_accuracy: 0.9320\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 27/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.2291 - accuracy: 0.9064 - val_loss: 0.1643 - val_accuracy: 0.9340\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 28/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.2158 - accuracy: 0.9122 - val_loss: 0.1982 - val_accuracy: 0.9280\n",
            "Epoch 29/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.2073 - accuracy: 0.9200 - val_loss: 0.1695 - val_accuracy: 0.9370\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 30/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.2141 - accuracy: 0.9126 - val_loss: 0.1774 - val_accuracy: 0.9350\n",
            "Epoch 31/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.2024 - accuracy: 0.9228 - val_loss: 0.1554 - val_accuracy: 0.9430\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 32/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.2097 - accuracy: 0.9202 - val_loss: 0.1587 - val_accuracy: 0.9420\n",
            "Epoch 33/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.2037 - accuracy: 0.9148 - val_loss: 0.1650 - val_accuracy: 0.9400\n",
            "Epoch 34/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.1916 - accuracy: 0.9262 - val_loss: 0.1920 - val_accuracy: 0.9320\n",
            "Epoch 35/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1902 - accuracy: 0.9236 - val_loss: 0.1531 - val_accuracy: 0.9420\n",
            "Epoch 36/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1923 - accuracy: 0.9206 - val_loss: 0.1535 - val_accuracy: 0.9440\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 37/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.1802 - accuracy: 0.9298 - val_loss: 0.1531 - val_accuracy: 0.9460\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 38/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1834 - accuracy: 0.9266 - val_loss: 0.1556 - val_accuracy: 0.9430\n",
            "Epoch 39/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.1868 - accuracy: 0.9238 - val_loss: 0.1475 - val_accuracy: 0.9440\n",
            "Epoch 40/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1817 - accuracy: 0.9228 - val_loss: 0.1537 - val_accuracy: 0.9440\n",
            "Epoch 41/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.1838 - accuracy: 0.9272 - val_loss: 0.1475 - val_accuracy: 0.9430\n",
            "Epoch 42/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1784 - accuracy: 0.9286 - val_loss: 0.1446 - val_accuracy: 0.9420\n",
            "Epoch 43/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.1734 - accuracy: 0.9302 - val_loss: 0.2032 - val_accuracy: 0.9280\n",
            "Epoch 44/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.1645 - accuracy: 0.9302 - val_loss: 0.1455 - val_accuracy: 0.9450\n",
            "Epoch 45/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.1712 - accuracy: 0.9298 - val_loss: 0.1566 - val_accuracy: 0.9420\n",
            "Epoch 46/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.1613 - accuracy: 0.9370 - val_loss: 0.1377 - val_accuracy: 0.9490\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 47/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1611 - accuracy: 0.9382 - val_loss: 0.1439 - val_accuracy: 0.9440\n",
            "Epoch 48/200\n",
            "167/167 [==============================] - 34s 202ms/step - loss: 0.1621 - accuracy: 0.9350 - val_loss: 0.1865 - val_accuracy: 0.9360\n",
            "Epoch 49/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1533 - accuracy: 0.9402 - val_loss: 0.1924 - val_accuracy: 0.9360\n",
            "Epoch 50/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1573 - accuracy: 0.9380 - val_loss: 0.1524 - val_accuracy: 0.9440\n",
            "Epoch 51/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1598 - accuracy: 0.9386 - val_loss: 0.1378 - val_accuracy: 0.9480\n",
            "Epoch 52/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1460 - accuracy: 0.9396 - val_loss: 0.1492 - val_accuracy: 0.9470\n",
            "Epoch 53/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1463 - accuracy: 0.9420 - val_loss: 0.1545 - val_accuracy: 0.9460\n",
            "Epoch 54/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1363 - accuracy: 0.9452 - val_loss: 0.1544 - val_accuracy: 0.9430\n",
            "Epoch 55/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.1607 - accuracy: 0.9346 - val_loss: 0.1919 - val_accuracy: 0.9330\n",
            "Epoch 56/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1406 - accuracy: 0.9446 - val_loss: 0.1486 - val_accuracy: 0.9470\n",
            "Epoch 57/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1444 - accuracy: 0.9400 - val_loss: 0.1372 - val_accuracy: 0.9460\n",
            "Epoch 58/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1382 - accuracy: 0.9472 - val_loss: 0.1358 - val_accuracy: 0.9470\n",
            "Epoch 59/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1376 - accuracy: 0.9462 - val_loss: 0.1361 - val_accuracy: 0.9460\n",
            "Epoch 60/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1312 - accuracy: 0.9494 - val_loss: 0.1568 - val_accuracy: 0.9490\n",
            "Epoch 61/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1301 - accuracy: 0.9498 - val_loss: 0.1353 - val_accuracy: 0.9440\n",
            "Epoch 62/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1333 - accuracy: 0.9490 - val_loss: 0.1343 - val_accuracy: 0.9470\n",
            "Epoch 63/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1312 - accuracy: 0.9492 - val_loss: 0.1390 - val_accuracy: 0.9510\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 64/200\n",
            "167/167 [==============================] - 35s 210ms/step - loss: 0.1300 - accuracy: 0.9518 - val_loss: 0.1475 - val_accuracy: 0.9510\n",
            "Epoch 65/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1322 - accuracy: 0.9474 - val_loss: 0.1463 - val_accuracy: 0.9480\n",
            "Epoch 66/200\n",
            "167/167 [==============================] - 35s 210ms/step - loss: 0.1320 - accuracy: 0.9514 - val_loss: 0.1374 - val_accuracy: 0.9500\n",
            "Epoch 67/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1221 - accuracy: 0.9524 - val_loss: 0.1499 - val_accuracy: 0.9520\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 68/200\n",
            "167/167 [==============================] - 35s 209ms/step - loss: 0.1301 - accuracy: 0.9506 - val_loss: 0.1375 - val_accuracy: 0.9480\n",
            "Epoch 69/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1215 - accuracy: 0.9524 - val_loss: 0.1750 - val_accuracy: 0.9420\n",
            "Epoch 70/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1235 - accuracy: 0.9516 - val_loss: 0.2261 - val_accuracy: 0.9220\n",
            "Epoch 71/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.1224 - accuracy: 0.9534 - val_loss: 0.1665 - val_accuracy: 0.9490\n",
            "Epoch 72/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1234 - accuracy: 0.9496 - val_loss: 0.1406 - val_accuracy: 0.9510\n",
            "Epoch 73/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1140 - accuracy: 0.9548 - val_loss: 0.1468 - val_accuracy: 0.9510\n",
            "Epoch 74/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1209 - accuracy: 0.9546 - val_loss: 0.1346 - val_accuracy: 0.9530\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 75/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1143 - accuracy: 0.9548 - val_loss: 0.1337 - val_accuracy: 0.9500\n",
            "Epoch 76/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1122 - accuracy: 0.9562 - val_loss: 0.1454 - val_accuracy: 0.9520\n",
            "Epoch 77/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1213 - accuracy: 0.9540 - val_loss: 0.1400 - val_accuracy: 0.9520\n",
            "Epoch 78/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1190 - accuracy: 0.9538 - val_loss: 0.1481 - val_accuracy: 0.9490\n",
            "Epoch 79/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.1100 - accuracy: 0.9616 - val_loss: 0.1335 - val_accuracy: 0.9500\n",
            "Epoch 80/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1108 - accuracy: 0.9560 - val_loss: 0.1306 - val_accuracy: 0.9530\n",
            "Epoch 81/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.1202 - accuracy: 0.9538 - val_loss: 0.1309 - val_accuracy: 0.9530\n",
            "Epoch 82/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1126 - accuracy: 0.9576 - val_loss: 0.1702 - val_accuracy: 0.9460\n",
            "Epoch 83/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1096 - accuracy: 0.9582 - val_loss: 0.1306 - val_accuracy: 0.9520\n",
            "Epoch 84/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1064 - accuracy: 0.9594 - val_loss: 0.1596 - val_accuracy: 0.9520\n",
            "Epoch 85/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.1025 - accuracy: 0.9592 - val_loss: 0.1359 - val_accuracy: 0.9500\n",
            "Epoch 86/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1078 - accuracy: 0.9580 - val_loss: 0.1759 - val_accuracy: 0.9410\n",
            "Epoch 87/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.1004 - accuracy: 0.9606 - val_loss: 0.1797 - val_accuracy: 0.9470\n",
            "Epoch 88/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.1006 - accuracy: 0.9616 - val_loss: 0.1308 - val_accuracy: 0.9510\n",
            "Epoch 89/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.1025 - accuracy: 0.9610 - val_loss: 0.1297 - val_accuracy: 0.9560\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 90/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.0959 - accuracy: 0.9652 - val_loss: 0.1465 - val_accuracy: 0.9540\n",
            "Epoch 91/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.1091 - accuracy: 0.9582 - val_loss: 0.1552 - val_accuracy: 0.9500\n",
            "Epoch 92/200\n",
            "167/167 [==============================] - 35s 209ms/step - loss: 0.0961 - accuracy: 0.9632 - val_loss: 0.1881 - val_accuracy: 0.9430\n",
            "Epoch 93/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.1004 - accuracy: 0.9626 - val_loss: 0.1872 - val_accuracy: 0.9480\n",
            "Epoch 94/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.0944 - accuracy: 0.9654 - val_loss: 0.1318 - val_accuracy: 0.9540\n",
            "Epoch 95/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.0941 - accuracy: 0.9620 - val_loss: 0.1806 - val_accuracy: 0.9460\n",
            "Epoch 96/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.0950 - accuracy: 0.9642 - val_loss: 0.2138 - val_accuracy: 0.9340\n",
            "Epoch 97/200\n",
            "167/167 [==============================] - 35s 209ms/step - loss: 0.0902 - accuracy: 0.9664 - val_loss: 0.1335 - val_accuracy: 0.9550\n",
            "Epoch 98/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.0893 - accuracy: 0.9666 - val_loss: 0.1682 - val_accuracy: 0.9500\n",
            "Epoch 99/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.0930 - accuracy: 0.9664 - val_loss: 0.1519 - val_accuracy: 0.9540\n",
            "Epoch 100/200\n",
            "167/167 [==============================] - 34s 203ms/step - loss: 0.0896 - accuracy: 0.9630 - val_loss: 0.1668 - val_accuracy: 0.9490\n",
            "Epoch 101/200\n",
            "167/167 [==============================] - 35s 208ms/step - loss: 0.0919 - accuracy: 0.9650 - val_loss: 0.1478 - val_accuracy: 0.9520\n",
            "Epoch 102/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.0998 - accuracy: 0.9616 - val_loss: 0.1586 - val_accuracy: 0.9510\n",
            "Epoch 103/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.0893 - accuracy: 0.9680 - val_loss: 0.1540 - val_accuracy: 0.9530\n",
            "Epoch 104/200\n",
            "167/167 [==============================] - 35s 207ms/step - loss: 0.0862 - accuracy: 0.9694 - val_loss: 0.1335 - val_accuracy: 0.9570\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 105/200\n",
            "167/167 [==============================] - 34s 205ms/step - loss: 0.0799 - accuracy: 0.9696 - val_loss: 0.1370 - val_accuracy: 0.9590\n",
            "INFO:tensorflow:Assets written to: /tmp/chkpoint/assets\n",
            "Epoch 106/200\n",
            "167/167 [==============================] - 34s 204ms/step - loss: 0.0898 - accuracy: 0.9638 - val_loss: 0.1380 - val_accuracy: 0.9560\n",
            "Epoch 107/200\n",
            "167/167 [==============================] - 35s 206ms/step - loss: 0.0834 - accuracy: 0.9696 - val_loss: 0.1977 - val_accuracy: 0.9410\n",
            "Epoch 108/200\n",
            "167/167 [==============================] - 34s 201ms/step - loss: 0.0847 - accuracy: 0.9682 - val_loss: 0.1440 - val_accuracy: 0.9530\n",
            "Epoch 109/200\n",
            "167/167 [==============================] - 34s 206ms/step - loss: 0.0815 - accuracy: 0.9672 - val_loss: 0.1551 - val_accuracy: 0.9520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQsE9c4TqbhH"
      },
      "source": [
        "# Recuperamos el mejor modelo del checkpoint y lo guardamos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8XZzVKzPltr",
        "outputId": "39b84336-662e-4fb8-ac1b-b1efad332fe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_with_vgg.load_weights('/tmp/chkpoint')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa8f5ed6610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGUzLSmrqbhI"
      },
      "source": [
        "model_with_vgg.save(ruta_archivos+\"model_with_finetunning_transfer_learning_vgg16_plus_data_augmentation.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igs38dfdqbhI"
      },
      "source": [
        "# Carguemos el modelo con  Transfer Learning sin data augmentation\n",
        "\n",
        "Aquí recogeremos el modelo y los datos de XY pasados por VGG16 post procesados guardados en NPZ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQuxzN1qbhJ"
      },
      "source": [
        "model_vgg16_fine_tuning = load_model(ruta_archivos+\"model_with_finetunning_transfer_learning_vgg16.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAxPYpB3qbhK"
      },
      "source": [
        "# Miremos que tal rinde el modelo en errores y accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "eQJPpXTRqbhK",
        "outputId": "d157d617-d0bb-416d-d241-b51bf0c10cb8"
      },
      "source": [
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnqgDgElqbhL",
        "outputId": "b084cdfe-6398-4e7c-d29f-08a5babdb007"
      },
      "source": [
        "_, acc = model_with_vgg.evaluate(x_test_scaled, y_test_encoded, verbose=0)\n",
        "print('Modelo con Fine Tunning Transfer Learning con Data Augmentation> %.3f' % (acc * 100.0))\n",
        "\n",
        "_, acc = model_vgg16_fine_tuning.evaluate(x_test_scaled, y_test_encoded, verbose=0)\n",
        "print('Modelo con Fine Tuning Transfer Learning sin Data Augmentaion> %.3f' % (acc * 100.0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Modelo con Fine Tunning Transfer Learning con Data Augmentation> 95.800\n",
            "Modelo con Fine Tuning Transfer Learning sin Data Augmentaion> 95.600\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}