{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morenourey/CHAT/blob/main/01_start_notebook_mnist_tf2_v0_(3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQQ504I8Gx7"
      },
      "source": [
        "![Nuclio logo](https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSsFMumb8Gx9"
      },
      "source": [
        "## Primer ejemplo de Red Neuronal para el Master de Data Science de Nuclio School\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhWumKZz8Gx9"
      },
      "source": [
        "Recordemos los pasos a seguiren la creación de código para entrenar una red neuronal:\n",
        "<ol>\n",
        "    <li>Importar librerias: Keras, PyPlot y Numpy (añado time y datetime para controlar los tiempos de entrenamiento)</li>\n",
        "    <li>Definamos una red inicial (apilando bloques)</li>\n",
        "    <li>Definimos (o creamos) nuestro optimizador, añadiendo nuestra función error</li>\n",
        "    <li>Preparamos los datos (en este caso los cargamos)</li>\n",
        "    <li>Empezamos con el entrenamiento</li>\n",
        "    <li>Miramos los resultados y pasamos a la crítica mordaz</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQCscALN8Gx-"
      },
      "source": [
        "## 1. Librerias\n",
        "\n",
        "Para empezar carguemos esas librerias que nos hacen falta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rn3er2G8Gx-"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras as ks\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFGzlYRK8Gx_"
      },
      "source": [
        "## 2. Arquitectura de red del modelo\n",
        "\n",
        "Construimos un modelo sencillo de red neuronal para los datos MNIST, que en resumen son:\n",
        "- Datos de entrada: imagenes de 28x28 pixeles con un canal de grises (valores de 0 a 255, enteros)\n",
        "- Datos de salida (labels): a cada imagen le otorgamos un valor de 0 a 9, un total de 10 classes\n",
        "\n",
        "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/05/Examples-from-the-MNIST-dataset.png\">\n",
        "\n",
        "Para montar la arquitectura de la red neuronal se sigue el método **.Sequential()** de Keras (de input a output):\n",
        "\n",
        "- **Entrada** - Una conversion de una matriz 2D de 28x28 pixeles a un vector - método Flatten\n",
        "- **Oculto** - Una capa densa (fully connected) con 16 neuronas y activación lineal\n",
        "- **Salida** - Una capa densa (fully connected) con 10 neuronas (**las 10 clases de salida**) y activación softmax\n",
        "\n",
        "<img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/11/Colored_neural_network_es.svg/300px-Colored_neural_network_es.svg.png\" decoding=\"async\" width=\"300\" height=\"361\" class=\"thumbimage\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/1/11/Colored_neural_network_es.svg/450px-Colored_neural_network_es.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/11/Colored_neural_network_es.svg/600px-Colored_neural_network_es.svg.png 2x\" data-file-width=\"296\" data-file-height=\"356\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7FTUgZ68GyA"
      },
      "outputs": [],
      "source": [
        "model = ks.Sequential()\n",
        "\n",
        "model.add(ks.layers.Flatten(input_shape=(__, __)))\n",
        "model.add(ks.layers.Dense(16, activation='linear'))\n",
        "model.add(ks.layers.Dense(__, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHEOUGWQO48i"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwC-fWOI8GyA"
      },
      "source": [
        "Para revisar un modelo, nos basta con llamar al método **.summary()** del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x00r8naF8GyA"
      },
      "source": [
        "tDel **.summary()** se extrae información muy relevante: el número de paràmetros por capa y el total a entrenar.4\n",
        "\n",
        "Fijaos que 28x28 son 784 valores, así que es lo que tenemos de entrada. Esos 784 neuronas se enlazan con 16 (16 * 784 pesos + 16 bias = 12560) y esas 16 con las 10 de salida (16 * 10 pesos + 10 bias). Un total de 12730 parametros que aprender  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSC9sd8B8GyB"
      },
      "source": [
        "## 3. Optimizador, función error\n",
        "\n",
        "Definimos los parametros del modelo para su entrenamiento:\n",
        "* **Loss** - Función de error (función de coste) - Optamos por la Sparse Categorical Crosstentropy porque estamos clasificando imagenes\n",
        "* **Optimizer** - que optimizador de la función de coste usaremos, en este ejemplo SGD (Stochastic gradient descent)\n",
        "* **Metrics** - que metrica usaremos para evaluar el modelo... en este caso se usa la Accuracy\n",
        "\n",
        "**Nota sobre SGD:** por defecto lleva un learning rate de 0.01 y sin momentum (valor de 0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJsgotKu8GyB"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='__',\n",
        "              loss='__',\n",
        "              metrics=['__'], )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_1HDHrQ8GyB"
      },
      "source": [
        "## 4. Preparamos los datos\n",
        "\n",
        "Cargamos los datos de MNIST de los datasets directamente de las librerias de Keras. Estos ya estan dispuestos en train and test\n",
        "\n",
        "**Detalle importante:**\n",
        "> La red neuronal requiere que los inputs sean números reales, y lo haremos forzando la division de los valores de dentro de las matrices 28x28 (que tienen valoress del 0 al 255) por 255.0 (un real)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e89ijD7D8GyB"
      },
      "outputs": [],
      "source": [
        "mnist = ks.datasets.mnist\n",
        "\n",
        "(*_train, *_train), (*_test, *_test) = mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZTxQHSh8GyC"
      },
      "source": [
        "Pintemos una muestra de las imagenes del dataset MNIST, a ver si se parece en algo a lo que esperamos.\n",
        "Primero, vemos que tipos de datos tengo, después mapeamos esas matrices en una escala de grises utilizando el método **.get_cmap()** de PlotLy con los nueve primeros números del dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jrQkt5C8GyC"
      },
      "outputs": [],
      "source": [
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
        "\n",
        "for i in range(9):\n",
        "    plt.subplot(330 + 1 + i)\n",
        "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray'))\n",
        "\n",
        "plt.subplots_adjust(hspace = 0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XmKYEXD8GyC"
      },
      "source": [
        "Como vamos a querer ir haciendo validación a la vez que entrenamos (muy practico)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3vX3DvY8GyD"
      },
      "outputs": [],
      "source": [
        "x_val = x_train[-10000:]\n",
        "y_val = y_train[-10000:]\n",
        "\n",
        "x_train = x_train[:-10000]\n",
        "y_train = y_train[:-10000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-iL4iQgO48j"
      },
      "outputs": [],
      "source": [
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Val: X=%s, y=%s' % (x_val.shape, y_val.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKBsl0Kx8GyD"
      },
      "source": [
        "## 5. Entrenamiento\n",
        "\n",
        "Ya podemos ponernos a entrenar el modelo!!\n",
        "\n",
        "Empezaremos con 30 epocs, es decir, 30 pasadas completas del dataset (que a su vez sera con mini-batches internamente), por defecto en Keras, **el batch_size es de 32**.\n",
        "\n",
        "El metodo .fit() nos permite, definir además si disponemos de varias CPUs, GPUs, y si queremos ir validando datos a cada fin de epoch.\n",
        "\n",
        "**Nota: Este fit, en mi laptop no tarda más de 2 minutos.** (por eso vale la pena capturar los tiempos, así podeis validar las capacidades de vuestro equipo y valorar Google Colab)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai3bATw68GyD"
      },
      "outputs": [],
      "source": [
        "t = time.perf_counter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXS7XIk_8GyD"
      },
      "outputs": [],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "    batch_size=__,\n",
        "    epochs=__,\n",
        "    validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApS_w0xn8GyE"
      },
      "outputs": [],
      "source": [
        "elapsed_time = datetime.timedelta(seconds=(time.perf_counter() - t))\n",
        "\n",
        "print('Tiempo de entrenamiento:', elapsed_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkmUDSFn8GyE"
      },
      "source": [
        "## 6. Evaluamos los resultados\n",
        "\n",
        "Obtengamos una grafica de como el error y la accuracy van evolucionando en cada epoch en los datos de entrenamiento y en la validación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY3ZPZCb8GyE"
      },
      "outputs": [],
      "source": [
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "plt.plot(history.history['val_loss'], color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='validation')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U39rpmYZ8GyE"
      },
      "source": [
        "Evaluemos el modelo contra los valores de testeo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZX-76Zx8GyF"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test,  y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBstpDNL8GyF"
      },
      "source": [
        "El coste podemos ver que es estable. Además la accuracy baila muchísimo. No se puede decir que sea un modelo muy bueno.\n",
        "\n",
        "Veamos que tipo de predicciones estoy obteniendo sobre el conjunto de test (vamos a pintar las imagenes y sus clasificaciones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9HSRAeQl8GyF"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djbcfnul8GyF"
      },
      "source": [
        "Una de las ventajas de Python es que hay montones de funciones y código realizado por terceras personas. Aquí me he fusilado unas bonitas funciones (que he adaptado un poco a mis necesidades) para poder pintar las imagenes, su label (ground truth) y las clasificaciones que hemos realizado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pj_Dqgrt8GyF"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(predicted_label,\n",
        "                                100*np.max(predictions_array),\n",
        "                                true_label),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YcjfyLA8GyF"
      },
      "source": [
        "Dibujamos los primeros digitos, con las predicciones y sus valores reales (un total de 20 imagenes, para no abusar de vuestros laptops)\n",
        "\n",
        "Coloreamos las prediciones correctas en azul y los fallos en rojo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ1mH0iH8GyG"
      },
      "outputs": [],
      "source": [
        "num_rows = 5\n",
        "num_cols = 4\n",
        "start = 650\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i+start, predictions[i+start], y_test, x_test)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i+start, predictions[i+start], y_test)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oq5fMC4v8GyG"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model.save('mnist_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}