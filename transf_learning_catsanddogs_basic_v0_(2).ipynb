{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/morenourey/ENTREGABLES/blob/main/transf_learning_catsanddogs_basic_v0_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xULjVynfIMip"
      },
      "source": [
        "![Nuclio logo](https://nuclio.school/wp-content/uploads/2018/12/nucleoDS-newBlack.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XsWCs2GtMPAw"
      },
      "source": [
        "# Connectar a Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6Jk6GTVMDW_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5FTXWKIM1Dx"
      },
      "source": [
        "# Librerias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YO-qvTSM3kX"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras as ks\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuGCNtaSOEPV"
      },
      "source": [
        "# Variables de entorno\n",
        "\n",
        "<font color=\"#FF0000\">Aquí definireis vuestra ruta del proyecto de perros y Gatos</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K7GC8BQOHV9"
      },
      "outputs": [],
      "source": [
        "ANCHO_IMAGEN = 150\n",
        "ALTURA_IMAGEN=150\n",
        "IMAGE_SIZE = (ANCHO_IMAGEN, ALTURA_IMAGEN)\n",
        "CANALES_IMAGENES = 3\n",
        "\n",
        "ruta_archivos = '/content/drive/MyDrive/00_Nuclio_DS_Master/Dogs-vs-cats/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CavLXOtgOTyb"
      },
      "source": [
        "# Cargaremos datos en NPZ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzVhzbmqOZ7i"
      },
      "outputs": [],
      "source": [
        "dict_npz = np.load(ruta_archivos+'xy_train_img.npz')\n",
        "x_train_img = dict_npz['x']\n",
        "y_train_img = dict_npz['y']\n",
        "\n",
        "dict_npz = np.load(ruta_archivos+'xy_test_img.npz')\n",
        "x_test_img = dict_npz['x']\n",
        "y_test_img = dict_npz['y']\n",
        "\n",
        "dict_npz = np.load(ruta_archivos+'xy_val_img.npz')\n",
        "x_val_img = dict_npz['x']\n",
        "y_val_img = dict_npz['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsjYQW0OPCFL"
      },
      "outputs": [],
      "source": [
        "x_train_scaled = x_train_img / 255.\n",
        "x_test_scaled = x_test_img / 255.\n",
        "x_val_scaled = x_val_img / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF01D2iGVd97"
      },
      "outputs": [],
      "source": [
        "y_train_img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF_SnUJNPtZ5"
      },
      "source": [
        "# Montamos la Red Neuronal\n",
        "\n",
        "## Cargar la parte de extraccion de features de VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBi8HNOBP1V2"
      },
      "outputs": [],
      "source": [
        "# Creemos una red que será extracción de features basada en VGG16 entrenada con ImageNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Xr76uANSfx7"
      },
      "outputs": [],
      "source": [
        "# Veamos como va lo de \"congelar\" capas de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezsy6QqSTfGk"
      },
      "source": [
        "## Pre-procesaremos las imagenes originales, pasandolas por VGG16, para poder usarlas en la parte de clasificacion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0xk4P7aTmEy"
      },
      "outputs": [],
      "source": [
        "# Llevamos las imagenes desde su origen al cuello de botella de VGG16, justo después del Flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kXmbiS9T6k2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO4I17PxUVOS"
      },
      "source": [
        "# Montemos la red de clasificación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro2wPiG1UZX0"
      },
      "outputs": [],
      "source": [
        "# Definamos el output de salida de la transformacion VGG16\n",
        "output_from_vgg16 = 0 #TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qDwi_ELUwHg"
      },
      "outputs": [],
      "source": [
        "model_post_vgg = ks.Sequential()\n",
        "\n",
        "model_post_vgg.add(ks.layers.InputLayer(input_shape=(output_from_vgg16)))\n",
        "model_post_vgg.add(ks.layers.Dense(512, activation='relu', input_shape=(output_from_vgg16,)))\n",
        "model_post_vgg.add(ks.layers.Dropout(0.3))\n",
        "model_post_vgg.add(ks.layers.Dense(512, activation='relu'))\n",
        "model_post_vgg.add(ks.layers.Dropout(0.3))\n",
        "model_post_vgg.add(ks.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_post_vgg.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgyjckmLWGV5"
      },
      "source": [
        "# Creamos un optimizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D-G7bQ2WKZL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lv5_11kWaP0"
      },
      "outputs": [],
      "source": [
        "new_adam = Adam(learning_rate=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGPweTyGWwiA"
      },
      "outputs": [],
      "source": [
        "model_post_vgg.compile(loss='binary_crossentropy', optimizer=new_adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bFrHu2sXCQB"
      },
      "source": [
        "# Early stopping!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20hx0uQFXA08"
      },
      "outputs": [],
      "source": [
        "callback = EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZKWdR2Na3Mm"
      },
      "source": [
        "# Encoding de etiquetas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xNzsi3Sa89O"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le.fit(y_train_img)\n",
        "y_train_encoded = le.transform(y_train_img)\n",
        "y_val_encoded = le.transform(y_val_img)\n",
        "y_test_encoded = le.transform(y_test_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rx2qT33pbWfy"
      },
      "outputs": [],
      "source": [
        "print(np.array(y_train_img))\n",
        "print(np.array(y_train_encoded))\n",
        "\n",
        "y_train_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5ewPTEFXOPb"
      },
      "source": [
        "# Entrenar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nLdIY2UXY4s"
      },
      "outputs": [],
      "source": [
        "history = model_post_vgg.fit(x=x_train_features_vgg, y=y_train_encoded, batch_size=512,\n",
        "                             epochs=10, callbacks=[callback],\n",
        "                             validation_data=(x_val_features_vgg, y_val_encoded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9wlK6qZkcyf"
      },
      "source": [
        "# Guardamos el modelo\n",
        "\n",
        "Aquí tenemos que guardar el modelo simple, pero tambien hemos de guardar, o bien el modelo de preproceso o bien los datos de test procesados en NPZ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obUoFlpXkcyg"
      },
      "outputs": [],
      "source": [
        "# Modelo post VGG16\n",
        "model_post_vgg.save(ruta_archivos+'model_with_basic_transfer_learning_post_vgg16.h5')\n",
        "\n",
        "# Datos procesados de test\n",
        "np.savez_compressed(ruta_archivos+'post_vgg16_test_data.npz', x=x_test_features_vgg, y=y_test_encoded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jPRKwC_kcyg"
      },
      "source": [
        "# Miremos que tal rinde el modelo en errores y accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKqHz-_mkcyg"
      },
      "outputs": [],
      "source": [
        "plt.title('Cross Entropy Loss')\n",
        "plt.plot(history.history['loss'], color='blue', label='train')\n",
        "plt.plot(history.history['val_loss'], color='orange', label='test')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Classification Accuracy')\n",
        "plt.plot(history.history['accuracy'], color='blue', label='train')\n",
        "plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LUGA9cgkcyh"
      },
      "outputs": [],
      "source": [
        "_, acc = model_post_vgg.evaluate(x_test_features_vgg, y_test_encoded, verbose=0)\n",
        "print('Modelo con Basic Transfer Learning > %.3f' % (acc * 100.0))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}